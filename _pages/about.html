<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html><body> <p>I am a Postdoctoral Research Fellow and Adjunct Faculty in Electrical &amp; Computer Engineering at the University of Massachusetts Amherst. My research builds <strong>dependable Edge AI systems</strong> for <strong>networked, resource-constrained platforms</strong> (IoT/embedded/CPS and multi-agent autonomy), where decisions must be made under hard constraints on <strong>latency, energy, and memory</strong>, and where <strong>dependence, partial observability, and distribution shift</strong> are the default operating conditions. :contentReference[oaicite:0]{index=0} :contentReference[oaicite:1]{index=1}</p> <h3 id="research-thesis-make-reliability-measurable-at-decision-time">Research thesis: make reliability measurable at decision time</h3> <p>Most ML pipelines still lean on two convenient assumptions: near-i.i.d. evaluation and unconstrained inference. In deployed edge autonomy, both assumptions break. My work designs for the real regime directly by co-designing:<br> <strong>(i)</strong> dependence-aware reliability signals, <strong>(ii)</strong> computation-aware inference controllers, and <strong>(iii)</strong> protocol-driven validation so systems can report calibrated uncertainty and cost, defer when warranted, and avoid silent failure. :contentReference[oaicite:2]{index=2}</p> <h3 id="active-projects-and-proof-points">Active projects and proof points</h3> <ul> <li> <strong>NSF CPS AERIAL (Co-PI; Thrust 2 Lead):</strong> I lead budget-aware learning-and-control and digital-twin validation protocols that report reliability in operational units (e.g., constraint violations and energy-per-decision) using replayable traces, targeting UAV swarm autonomy in a search-and-rescue setting. :contentReference[oaicite:3]{index=3} :contentReference[oaicite:4]{index=4}</li> <li> <strong>TinyGNN + Low-rank training for deployable graph inference:</strong> I develop compact graph inference primitives that make decision-time cost controllable. A low-rank message-passing architecture achieves up to <strong>60× model size reduction</strong> with only ~<strong>2%</strong> best-case performance drop, enabling HW/SW co-design via tunable rank/precision knobs. :contentReference[oaicite:5]{index=5}</li> <li> <strong>Budgeted test-time inference for foundation models (CGES):</strong> We co-developed <strong>Confidence-Guided Early Stopping</strong>, a Bayesian stopping rule that uses confidence as evidence and halts sampling when posterior mass crosses a threshold (or a hard budget binds). Across five reasoning benchmarks, CGES reduces model calls by <strong>69.4%</strong> while matching self-consistency accuracy. :contentReference[oaicite:6]{index=6}</li> <li> <strong>Foundations: minimax sample complexity for GNNs under dependence/topology:</strong> I develop minimax limits that characterize when graph topology makes learning intrinsically label-inefficient, yielding diagnostics that predict when more labels help versus when gains require changing mixing geometry. :contentReference[oaicite:7]{index=7}</li> </ul> <h3 id="future-research-directions">Future research directions</h3> <p>My program advances a single goal: <strong>dependable Edge AI under dependence and hard budgets</strong>, through three composable thrusts:</p> <ol> <li> <strong>Computation-aware inference controllers</strong> (adaptive rank/precision/sampling depth with explicit accuracy–efficiency tradeoffs). :contentReference[oaicite:8]{index=8}</li> <li> <strong>Protocol-driven validation + lightweight monitoring</strong> (replayable stress tests, operational metrics like Joules/decision, and label-free drift monitors). :contentReference[oaicite:9]{index=9} :contentReference[oaicite:10]{index=10}</li> <li> <strong>Dependence-aware learning foundations</strong> (evaluation and uncertainty for relational/time-varying streams; topology-aware diagnostics). :contentReference[oaicite:11]{index=11}</li> </ol> <h3 id="teaching-and-why-students-dont-hate-it">Teaching (and why students don’t hate it)</h3> <p>I teach ML, generative models, DSP, image processing, and data science foundations. My goal is to turn technical knowledge into durable engineering ability: students learn to specify requirements, build baselines, debug under shift/partial observability, and deliver reproducible artifacts that justify accuracy–reliability–cost tradeoffs. :contentReference[oaicite:12]{index=12}<br> My UMass evaluations reflect strong execution and clarity (<strong>overall instructor effectiveness 4.7/5.0</strong>, with <strong>5.0/5.0</strong> on preparation and use of class time in a recent offering). :contentReference[oaicite:13]{index=13} :contentReference[oaicite:14]{index=14}</p> <h3 id="students-collaborators-and-funding">Students, collaborators, and funding</h3> <p>I am building research around shared interfaces that make systems dependable in practice: <strong>reliability contracts, telemetry/monitoring, and trace-based evaluation suites</strong> spanning Networking/IoT, embedded/SoC, and autonomy. :contentReference[oaicite:15]{index=15}<br> I currently mentor PhD and undergraduate researchers and regularly collaborate across ML systems and wireless/autonomy. :contentReference[oaicite:16]{index=16}</p> <p><strong>If you are interested in dependable ML systems for edge autonomy, resource-aware graph learning, or budgeted inference for foundation models, feel free to reach out.</strong></p> </body></html>